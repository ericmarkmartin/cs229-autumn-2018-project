{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from src import vectorize\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names = ['PERIOD', 'QMARK', 'EXPOINT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = vectorize.tokens_to_bag_of_words('../data/processed/merged_tok.txt', one_hot_y=False)\n",
    "train, dev, test = vectorize.train_dev_test_split(X, y, 0.05, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = train\n",
    "y_train = y_train.ravel()\n",
    "\n",
    "x_dev, y_dev = dev\n",
    "y_dev = y_dev.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
       "            oob_score=False, random_state=229, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100, random_state=229)\n",
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(x_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      PERIOD       0.86      0.99      0.92      1942\n",
      "       QMARK       0.71      0.27      0.39       198\n",
      "     EXPOINT       0.65      0.22      0.33       230\n",
      "\n",
      "   micro avg       0.85      0.85      0.85      2370\n",
      "   macro avg       0.74      0.49      0.55      2370\n",
      "weighted avg       0.83      0.85      0.82      2370\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_dev, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1914,   10,   18],\n",
       "       [ 135,   54,    9],\n",
       "       [ 167,   12,   51]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_dev, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      PERIOD       0.82      1.00      0.90      1942\n",
      "       QMARK       0.00      0.00      0.00       198\n",
      "     EXPOINT       0.00      0.00      0.00       230\n",
      "\n",
      "   micro avg       0.82      0.82      0.82      2370\n",
      "   macro avg       0.27      0.33      0.30      2370\n",
      "weighted avg       0.67      0.82      0.74      2370\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ericmarkmartin/.virtualenvs/cs229-autumn-2018-project-3R6jIYo2/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_dev, np.zeros_like(y_dev), target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1942,    0,    0],\n",
       "       [ 198,    0,    0],\n",
       "       [ 230,    0,    0]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_dev, np.zeros_like(y_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "guesses = [0]*1942 + [1]*198 + [2]*230"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle(guesses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "guesses[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      PERIOD       0.82      0.82      0.82      1942\n",
      "       QMARK       0.10      0.10      0.10       198\n",
      "     EXPOINT       0.09      0.09      0.09       230\n",
      "\n",
      "   micro avg       0.69      0.69      0.69      2370\n",
      "   macro avg       0.34      0.34      0.34      2370\n",
      "weighted avg       0.69      0.69      0.69      2370\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1589,  155,  198],\n",
       "       [ 166,   20,   12],\n",
       "       [ 187,   23,   20]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(classification_report(y_dev, guesses, target_names=target_names))\n",
    "confusion_matrix(y_dev, guesses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      PERIOD       0.82      1.00      0.90      1942\n",
      "       QMARK       0.00      0.00      0.00       198\n",
      "     EXPOINT       0.00      0.00      0.00       230\n",
      "\n",
      "   micro avg       0.82      0.82      0.82      2370\n",
      "   macro avg       0.27      0.33      0.30      2370\n",
      "weighted avg       0.67      0.82      0.74      2370\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ericmarkmartin/.virtualenvs/cs229-autumn-2018-project-3R6jIYo2/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_dev, np.zeros_like(y_dev), target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      PERIOD       0.83      0.83      0.83      1942\n",
      "       QMARK       0.14      0.13      0.14       198\n",
      "     EXPOINT       0.11      0.10      0.11       230\n",
      "\n",
      "   micro avg       0.70      0.70      0.70      2370\n",
      "   macro avg       0.36      0.36      0.36      2370\n",
      "weighted avg       0.70      0.70      0.70      2370\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1618,  139,  185],\n",
       "       [ 159,   26,   13],\n",
       "       [ 184,   22,   24]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "periods, qmarks, expoints = np.bincount(y_train)\n",
    "priors = np.concatenate((np.repeat(0, periods), np.repeat(1, qmarks), np.repeat(2, expoints)))\n",
    "np.random.seed(229)\n",
    "guesses = []\n",
    "macro_avgs = []\n",
    "for _ in range(100):\n",
    "    guess = np.random.choice(priors, size=len(y_dev))\n",
    "    guesses.append(guess)\n",
    "    macro_avgs.append(classification_report(y_dev, guess, output_dict=True)['macro avg']['f1-score'])\n",
    "\n",
    "best = guesses[macro_avgs.index(max(macro_avgs))]\n",
    "print(classification_report(y_dev, best, target_names=target_names))\n",
    "confusion_matrix(y_dev, best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test, y_test = test\n",
    "y_test = y_test.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      PERIOD       0.81      0.83      0.82      1932\n",
      "       QMARK       0.14      0.13      0.14       198\n",
      "     EXPOINT       0.08      0.07      0.07       240\n",
      "\n",
      "   micro avg       0.69      0.69      0.69      2370\n",
      "   macro avg       0.34      0.34      0.34      2370\n",
      "weighted avg       0.68      0.69      0.69      2370\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1597,  140,  195],\n",
       "       [ 162,   26,   10],\n",
       "       [ 202,   21,   17]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best = guesses[macro_avgs.index(max(macro_avgs))]\n",
    "print(classification_report(y_test, best, target_names=target_names))\n",
    "confusion_matrix(y_test, best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.32223591653771183"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_report(y_dev, guesses[0], output_dict=True)['macro avg']['f1-score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs229-autumn-2018-project-3R6jIYo2",
   "language": "python",
   "name": "cs229-autumn-2018-project-3r6jiyo2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
